services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    command: serve

  model-puller:
    image: busybox
    depends_on:
      - ollama
    command:
      - sh
      - -c
      - |
        sleep 5
        echo "============ Pulling '${MODEL:-llama3}' model..."
        wget -q http://ollama:11434/api/pull --post-data='{"name": "${MODEL:-llama3}", "stream": true}'
        echo "============ Model pulled."

  server:
    build: .
    environment:
      SPRING_AI_OLLAMA_BASE_URL: http://ollama:11434
      SPRING_AI_OLLAMA_CHAT_OPTIONS_MODEL: ${MODEL:-llama3}
    ports:
      - "8080:8080"

  web:
    image: httpd
    ports:
      - "8081:80"
    volumes:
      - ./web:/usr/local/apache2/htdocs
volumes:
  ollama:
